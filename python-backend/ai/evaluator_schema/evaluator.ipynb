{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An rag workflow for evaluating the performance of Performed interview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tech_stack': 'html, css ,js', 'position': 'frontend developer', 'question_count': 5, 'difficulty': 'beginner', 'conversation_history': [{'role': 'interviewer', 'content': \"Hello! I'm your AI interviewer for today's frontend developer interview.\\n\\nI see your tech stack includes: html, css ,js\\n\\nLet's start with something fundamental. Can you explain what html is and describe one project where you've used it effectively?\"}, {'role': 'candidate', 'content': 'HTML (HyperText Markup Language) is the standard language used to structure content on the web, defining elements like headings, paragraphs, links, and images.It forms the backbone of every webpage, often paired with CSS for styling and JavaScript for interactivity.I used HTML effectively in a personal portfolio project, where I built a responsive multi-page site to showcase my development skills.It included semantic HTML tags for better accessibility and SEO.The project integrated images, forms, and navigation menus, giving a professional and user-friendly experience.'}, {'role': 'interviewer', 'content': \"That's a great example of using semantic HTML! Since you mentioned using semantic tags for accessibility and SEO in your portfolio, can you walk me through how you would structure the HTML for a navigation menu that includes a logo, three main links, and a mobile hamburger menu - specifically focusing on which semantic elements you'd choose and why?\"}, {'role': 'candidate', 'content': 'I’d wrap the entire navigation in a `<header>` element since it represents introductory content or site navigation.Inside it, I’d use a `<nav>` element to semantically indicate the main navigation section.The logo would be wrapped in an `<a>` tag (inside `<div>` or `<span>`), usually with the site name in an `<h1>` for branding and SEO.The three main links would go in an unordered list `<ul>` with each link inside a `<li>` and `<a>` for semantic structure and accessibility.The mobile hamburger menu could be a `<button>` with an accessible label (`aria-label=\"Open menu\"`), ensuring it’s usable for screen readers.Example:```html<header>  <nav>    <a href=\"/\" class=\"logo\">      <h1>MyPortfolio</h1>    </a>    <ul>      <li><a href=\"#about\">About</a></li>      <li><a href=\"#projects\">Projects</a></li>      <li><a href=\"#contact\">Contact</a></li>    </ul>    <button aria-label=\"Open menu\" class=\"hamburger\">☰</button>  </nav></header>```'}, {'role': 'interviewer', 'content': \"Great structure! I can see you're thinking about accessibility with the `aria-label` and semantic elements. Since you mentioned the mobile hamburger menu, let's dive into the CSS side - can you show me how you would write the CSS to make this navigation responsive? Specifically, how would you hide the regular menu and show the hamburger button on mobile screens, and what CSS properties would you use to achieve a clean mobile-first responsive design?\"}, {'role': 'candidate', 'content': 'i dont know'}, {'role': 'interviewer', 'content': \"That's perfectly fine! Let's take a step back - since you're familiar with the HTML structure we just discussed, can you show me how you would write just the basic CSS to style the navigation horizontally on desktop screens? Focus on making the logo, navigation links, and hamburger button appear in a single row, and don't worry about the mobile responsive part yet.\"}, {'role': 'candidate', 'content': 'i dont know'}, {'role': 'interviewer', 'content': \"No worries at all! Let's try something even more basic - can you show me how you would write CSS to change the color of the navigation links to blue and remove the underline from them?\"}, {'role': 'candidate', 'content': 'i dont know'}], 'is_complete': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_transcripts(file_path):\n",
    "    \"\"\"\n",
    "    Load transcripts from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file containing the transcripts.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the transcripts.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the file doesn't exist.\n",
    "        json.JSONDecodeError: If the file contains invalid JSON.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            transcripts = json.load(f)\n",
    "            return transcripts\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading transcripts: {e}\")\n",
    "        raise\n",
    "\n",
    "print(load_transcripts(r'../../interviews/627dc248.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, END,START\n",
    "\n",
    "\n",
    "\n",
    "from schema import (\n",
    "    TechnicalSkillAssessment,\n",
    "    ProblemSolvingInstance,\n",
    "    EvaluationWorkFlowState,\n",
    "    ConfidenceLevel,\n",
    "    ProficiencyLevel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded interview data:\n",
      "{'tech_stack': 'langchain,langgraph,ai', 'position': 'ai engineering', 'question_count': 5, 'difficulty': 'beginner', 'conversation_history': [{'role': 'interviewer', 'content': \"Hello! I'm your AI interviewer for today's ai engineering interview.\\n\\nI see your tech stack includes: langchain,langgraph,ai\\n\\nLet's start with something fundamental. Can you explain what langchain is and describe one project where you've used it effectively?\"}, {'role': 'candidate', 'content': 'LangChain is a framework for building applications powered by large language models (LLMs), designed to make it easier to connect models with data sources, APIs, and workflows.It provides tools for prompt management, memory, chaining multiple model calls, and integrating with retrieval systems.I used LangChain effectively to build a retrieval-augmented chatbot that answered company policy questions for employees.It integrated with a vector database to fetch relevant documents before generating answers.This reduced repetitive HR queries by over 70% and improved response accuracy.'}, {'role': 'interviewer', 'content': \"Great job explaining your RAG chatbot! I'm curious about the vector database integration you mentioned. Can you walk me through how you chose which embedding model to use for converting those policy documents into vectors, and what specific challenges you faced when implementing the retrieval component?\"}, {'role': 'candidate', 'content': 'how are you'}, {'role': 'interviewer', 'content': 'I noticed you asked \"how are you\" instead of answering my question about the embedding model choice and retrieval challenges. That\\'s okay - let\\'s take a step back.\\n\\nSince you mentioned building a RAG chatbot with vector database integration, can you explain what a vector database is and why it\\'s particularly useful for retrieval-augmented generation systems?'}, {'role': 'candidate', 'content': 'i love you'}, {'role': 'interviewer', 'content': 'I understand this might be a challenging topic for you - that\\'s perfectly okay! Let\\'s start with something more foundational.\\n\\nCan you explain what an embedding is in the context of AI and natural language processing? For example, if I have the sentence \"The cat sat on the mat,\" what would an embedding represent?'}, {'role': 'candidate', 'content': 'In AI and NLP, an **embedding** is a numerical vector representation of text (words, sentences, or documents) that captures its meaning in a way machines can understand.Instead of treating text as raw strings, embeddings map it into a high-dimensional space where similar meanings are close together.For the sentence *\"The cat sat on the mat\"*, its embedding would be a list of numbers representing its semantic meaning — not the words themselves.This means that a similar sentence like *\"A cat rested on a mat\"* would have a vector close to it in that space.Embeddings are used for tasks like semantic search, clustering, and recommendation systems.'}, {'role': 'interviewer', 'content': 'Great explanation of embeddings! Now let\\'s connect this to retrieval - can you explain how you would actually use these embeddings to find relevant information in a vector database? For instance, if a user asks \"Tell me about feline behavior,\" how would the system use the embedding of this query to retrieve documents about cats?'}, {'role': 'candidate', 'content': 'Here’s how it works step-by-step:1. **Convert the query to an embedding** – The system passes *\"Tell me about feline behavior\"* through an embedding model (e.g., OpenAI’s `text-embedding-ada-002`) to get a numerical vector.2. **Compare against stored document embeddings** – Each document in the vector database (e.g., Pinecone, Weaviate, FAISS) has its own precomputed embedding.3. **Measure similarity** – The database uses a similarity metric like cosine similarity or dot product to compare the query vector with all stored vectors.4. **Retrieve top matches** – Documents with embeddings closest to the query embedding (meaning semantically similar) are returned as the most relevant.5. **Send results to the LLM** – The retrieved documents are then fed into the language model so it can answer with context, e.g., explaining cat behavior.So even if the query doesn’t contain the exact word “cat,” the embedding’s semantic understanding links *“feline”* to relevant documents about cats.'}], 'is_complete': True}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'current_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(interview_data)\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Create an initial state with required fields\u001b[39;00m\n\u001b[32m     85\u001b[39m initial_evaluation_state = {\n\u001b[32m     86\u001b[39m     interview_data: interview_data,\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[43mcurrent_step\u001b[49m: \u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m     errors: [],  \u001b[38;5;66;03m# Initialize empty errors list\u001b[39;00m\n\u001b[32m     89\u001b[39m     technical_skills: [],\n\u001b[32m     90\u001b[39m     technical_consistency_score: \u001b[32m0\u001b[39m,\n\u001b[32m     91\u001b[39m     technical_depth_score: \u001b[32m0\u001b[39m,\n\u001b[32m     92\u001b[39m     technical_knowledge_gaps: [],\n\u001b[32m     93\u001b[39m     technical_strengths: []\n\u001b[32m     94\u001b[39m }\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Call the technical evaluator function\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mcalling llm with updated state\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'current_step' is not defined"
     ]
    }
   ],
   "source": [
    "def llm1_technical_evaluator(state: EvaluationWorkFlowState) -> EvaluationWorkFlowState:\n",
    "    \"\"\"LLM 1: Technical Skills Evaluator - Updates technical fields in state\"\"\"\n",
    "    print('LLM1 got called') \n",
    "\n",
    "    print(f'State = {state}')\n",
    "    try:\n",
    "        system_prompt = \"\"\"You are a Senior Technical Interviewer specializing in evaluating technical skills and knowledge depth.\n",
    "\n",
    "Your task is to analyze the interview conversation and assess the candidate's technical competencies.\n",
    "\n",
    "Focus on:\n",
    "1. Depth of technical understanding\n",
    "2. Specific skills demonstrated (HTML, CSS, JavaScript, frameworks, etc.)\n",
    "3. Quality of technical explanations\n",
    "4. Knowledge gaps and areas needing improvement\n",
    "\n",
    "Return your analysis in JSON format with the following structure:\n",
    "{\n",
    "    \"technical_skills\": [\n",
    "        {\n",
    "            \"skill_name\": \"JavaScript\",\n",
    "            \"proficiency_level\": \"intermediate\",\n",
    "            \"evidence\": [\"Explained closures correctly\", \"Mentioned ES6 features\"],\n",
    "            \"confidence\": \"high\",\n",
    "            \"comments\": \"Good understanding shown\"\n",
    "        }\n",
    "    ],\n",
    "    \"technical_consistency_score\": 7,\n",
    "    \"technical_depth_score\": 6,\n",
    "    \"technical_knowledge_gaps\": [\"Advanced React patterns\", \"Testing frameworks\"],\n",
    "    \"technical_strengths\": [\"Strong JavaScript fundamentals\", \"Good understanding of async programming\"]\n",
    "}\n",
    "\n",
    "IMPORTANT: \n",
    "- Use \"evidence\" not \"evidance\"\n",
    "- Use \"confidence\" not \"confidence_level\" \n",
    "- Always include \"comments\" field for each skill\n",
    "- proficiency_level must be one of: \"beginner\", \"intermediate\", \"advanced\", \"expert\"\n",
    "- confidence must be one of: \"low\", \"medium\", \"high\", \"very_high\"\n",
    "\n",
    "Be thorough but fair in your assessment.\"\"\"\n",
    "\n",
    "        human_prompt = f\"\"\"Analyze this interview conversation for technical skills:\n",
    "\n",
    "Interview Data: {state.interview_data}\n",
    "\n",
    "Return only valid JSON following the specified structure.\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=human_prompt)\n",
    "        ]\n",
    "        print('calling llm1')\n",
    "        response = llm.invoke(messages)\n",
    "        print(\"Raw LLM Response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Parse JSON response\n",
    "        parser = JsonOutputParser()\n",
    "        result = parser.parse(response.content)\n",
    "        \n",
    "        # Update state with technical evaluation results\n",
    "        state.technical_skills = [TechnicalSkillAssessment(**skill) for skill in result.get(\"technical_skills\", [])]\n",
    "        state.technical_consistency_score = result.get(\"technical_consistency_score\", 0)\n",
    "        state.technical_depth_score = result.get(\"technical_depth_score\", 0)\n",
    "        state.technical_knowledge_gaps = result.get(\"technical_knowledge_gaps\", [])\n",
    "        state.technical_strengths = result.get(\"technical_strengths\", [])\n",
    "        \n",
    "        state.current_step = \"llm1_completed\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"LLM1 Technical Evaluator error: {str(e)}\"\n",
    "        state.errors.append(error_msg)\n",
    "        print(f\"Error: {error_msg}\")\n",
    "        \n",
    "    return state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load interview data\n",
    "    interview_data2 = load_transcripts(r'../../interviews/1f4db5f1.json')\n",
    "    print(\"Loaded interview data:\")\n",
    "    print(interview_data2)\n",
    "    \n",
    "    # Create an initial state with required fields\n",
    "    initial_evaluation_state = {\n",
    "        interview_data: interview_data2,\n",
    "        current_step: \"start\",\n",
    "        errors: [],  # Initialize empty errors list\n",
    "        technical_skills: [],\n",
    "        technical_consistency_score: 0,\n",
    "        technical_depth_score: 0,\n",
    "        technical_knowledge_gaps: [],\n",
    "        technical_strengths: []\n",
    "    }\n",
    "    \n",
    "    # Call the technical evaluator function\n",
    "    print('calling llm with updated state')\n",
    "    updated_state = llm1_technical_evaluator(initial_evaluation_state)\n",
    "    print(updated_state)\n",
    "    # Print results\n",
    "    print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "    print(\"Technical Skills:\")\n",
    "    for skill in updated_state.technical_skills:\n",
    "        print(f\"  - {skill.skill_name}: {skill.proficiency_level}\")\n",
    "        print(f\"    Confidence: {skill.confidence}\")\n",
    "        print(f\"    Evidence: {skill.evidence}\")\n",
    "        print(f\"    Comments: {skill.comments}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Technical Consistency Score:\", updated_state.technical_consistency_score)\n",
    "    print(\"Technical Depth Score:\", updated_state.technical_depth_score)\n",
    "    print(\"Knowledge Gaps:\", updated_state.technical_knowledge_gaps)\n",
    "    print(\"Technical Strengths:\", updated_state.technical_strengths)\n",
    "    # print(\"Errors:\", updated_state.errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
