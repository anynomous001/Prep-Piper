// "use client"

// import { useState, useCallback, useRef, useEffect } from "react"
// import { io, Socket } from "socket.io-client"
// import type {
//   InterviewSession,
//   InterviewQuestion,
//   InterviewResponse,
// } from "@/lib/types"

// export type InterviewState =
//   | "idle"
//   | "connecting"
//   | "active"
//   | "processing"
//   | "waiting_for_next"
//   | "completed"

// // Singleton WebSocket connection to prevent React Strict Mode issues
// class SingletonSocket {
//   private static instance: Socket | null = null
//   private static connecting = false

//   static async getInstance(): Promise<Socket> {
//     if (SingletonSocket.instance?.connected) {
//       return SingletonSocket.instance
//     }

//     if (SingletonSocket.connecting) {
//       // Wait for the current connection attempt
//       return new Promise((resolve) => {
//         const checkConnection = () => {
//           if (SingletonSocket.instance?.connected) {
//             resolve(SingletonSocket.instance)
//           } else if (!SingletonSocket.connecting) {
//             // Connection failed, try again
//             SingletonSocket.getInstance().then(resolve)
//           } else {
//             setTimeout(checkConnection, 100)
//           }
//         }
//         checkConnection()
//       })
//     }

//     SingletonSocket.connecting = true

//     try {
//       const wsUrl = process.env.NEXT_PUBLIC_WS_URL || "http://localhost:3001"
      
//       if (SingletonSocket.instance) {
//         SingletonSocket.instance.removeAllListeners()
//         SingletonSocket.instance.disconnect()
//       }

//       SingletonSocket.instance = io(wsUrl, {
//         transports: ['websocket'],
//         timeout: 10000,
//         autoConnect: false,
//         forceNew: true,
//       })

//       return new Promise((resolve, reject) => {
//         const socket = SingletonSocket.instance!

//         const connectTimeout = setTimeout(() => {
//           SingletonSocket.connecting = false
//           reject(new Error('Connection timeout'))
//         }, 10000)

//         socket.on('connect', () => {
//           clearTimeout(connectTimeout)
//           SingletonSocket.connecting = false
//           console.log('‚úÖ Singleton socket connected')
//           resolve(socket)
//         })

//         socket.on('connect_error', (error) => {
//           clearTimeout(connectTimeout)
//           SingletonSocket.connecting = false
//           console.error('‚ùå Singleton socket connection error:', error)
//           reject(error)
//         })

//         socket.connect()
//       })
//     } catch (error) {
//       SingletonSocket.connecting = false
//       throw error
//     }
//   }

//   static disconnect(): void {
//     if (SingletonSocket.instance) {
//       SingletonSocket.instance.removeAllListeners()
//       SingletonSocket.instance.disconnect()
//       SingletonSocket.instance = null
//     }
//     SingletonSocket.connecting = false
//   }
// }

// export function useInterview() {
//   // State hooks
//   const [session, setSession] = useState<InterviewSession | null>(null)
//   const [currentQuestion, setCurrentQuestion] = useState<InterviewQuestion | null>(null)
//   const [transcript, setTranscript] = useState<string[]>([])
//   const [interimTranscript, setInterimTranscript] = useState("")
//   const [isRecording, setIsRecording] = useState(false)
//   const [isPlaying, setIsPlaying] = useState(false)
//   const [audioUrl, setAudioUrl] = useState<string | null>(null)
//   const [interviewState, setInterviewState] = useState<InterviewState>("idle")
//   const [progress, setProgress] = useState(0)
//   const [responses, setResponses] = useState<InterviewResponse[]>([])
//   const [error, setError] = useState<string | null>(null)
//   const [isConnected, setIsConnected] = useState(false)

//   // Refs
//   const audioRef = useRef<HTMLAudioElement | null>(null)
//   const recognitionRef = useRef<any>(null)
//   const mediaRecorderRef = useRef<MediaRecorder | null>(null)
//   const mediaStreamRef = useRef<MediaStream | null>(null)
//   const audioChunksRef = useRef<Blob[]>([])
//   const socketRef = useRef<Socket | null>(null)
//   const eventHandlersSetup = useRef(false)
//   const isRecordingRef = useRef(false) // Track recording state to prevent double starts

//   // Utility functions
//   const cleanup = useCallback(() => {
//     console.log('üßπ Cleaning up media resources...')
    
//     const cleanupPromises: Promise<void>[] = []

//     // Stop speech recognition
//     if (recognitionRef.current) {
//       cleanupPromises.push(
//         new Promise<void>((resolve) => {
//           try {
//             recognitionRef.current.onend = () => {
//               recognitionRef.current = null
//               resolve()
//             }
//             recognitionRef.current.stop()
//           } catch (e) {
//             console.log('Speech recognition already stopped')
//             resolve()
//           }
//         })
//       )
//     }
    
//     // Stop media recorder
//     if (mediaRecorderRef.current?.state !== 'inactive') {
//       cleanupPromises.push(
//         new Promise<void>((resolve) => {
//           try {
//             mediaRecorderRef.current!.onstop = () => {
//               mediaRecorderRef.current = null
//               resolve()
//             }
//             mediaRecorderRef.current!.stop()
//           } catch (e) {
//             console.log('Media recorder already stopped')
//             resolve()
//           }
//         })
//       )
//     }
    
//     // Stop media stream tracks
//     if (mediaStreamRef.current) {
//       cleanupPromises.push(
//         new Promise<void>((resolve) => {
//           mediaStreamRef.current!.getTracks().forEach(track => {
//             track.stop()
//             console.log('üé§ Media track stopped:', track.kind)
//           })
//           mediaStreamRef.current = null
//           resolve()
//         })
//       )
//     }
    
//     // Stop audio playback
//     if (audioRef.current) {
//       cleanupPromises.push(
//         new Promise<void>((resolve) => {
//           audioRef.current!.onended = () => {
//             audioRef.current = null
//             resolve()
//           }
//           audioRef.current!.pause()
//           resolve() // Resolve immediately after pause
//         })
//       )
//     }
    
//     // Wait for all cleanup operations to complete
//     Promise.all(cleanupPromises).finally(() => {
//       setIsRecording(false)
//       setIsPlaying(false)
//       isRecordingRef.current = false
//       audioChunksRef.current = []
//     })
//   }, [])

//   // Audio control functions
//   const playAudio = useCallback((url?: string) => {
//     const audioSrc = url || audioUrl
//     if (audioSrc) {
//       console.log('üîä Playing audio:', audioSrc)
//       if (audioRef.current) {
//         audioRef.current.pause()
//       }
//       audioRef.current = new Audio(audioSrc)
//       audioRef.current.play().then(() => {
//         setIsPlaying(true)
//       }).catch((e) => {
//         console.error('Failed to play audio:', e)
//         setError('Failed to play audio')
//       })
      
//       audioRef.current.onended = () => {
//         setIsPlaying(false)
//         console.log('üîä Audio playback completed')
//       }
      
//       audioRef.current.onerror = (e) => {
//         console.error('Audio playback error:', e)
//         setError('Audio playback error')
//         setIsPlaying(false)
//       }
//     }
//   }, [audioUrl])

//   const pauseAudio = useCallback(() => {
//     if (audioRef.current) {
//       audioRef.current.pause()
//       setIsPlaying(false)
//     }
//   }, [])

//   // Basic controls
//   const nextQuestion = useCallback(() => {
//     setInterviewState("waiting_for_next")
//     setProgress((p) => Math.min(p + 20, 100))
//   }, [])

//   const endInterview = useCallback(() => {
//     if (session?.id && socketRef.current?.connected) {
//       socketRef.current.emit("endInterview", { sessionId: session.id })
//     }
//     setInterviewState("completed")
//     setProgress(100)
//     cleanup()
//   }, [session?.id, cleanup])

//   // WebSocket and Media setup
//   const setupEventHandlers = useCallback((socket: Socket) => {
//     if (eventHandlersSetup.current) return
    
//     console.log('üîß Setting up interview event handlers')

//     // Connection events
//     socket.on('connect', () => {
//       console.log('‚úÖ Interview socket connected')
//       setIsConnected(true)
//     })

//     socket.on('disconnect', () => {
//       console.log('üîå Interview socket disconnected')
//       setIsConnected(false)
//       eventHandlersSetup.current = false
//     })

//     socket.on('connect_error', (error) => {
//       console.error('‚ùå Interview socket connection error:', error)
//       setError(`Connection error: ${error.message}`)
//       setIsConnected(false)
//     })

//     // STT events
//     socket.on('sttConnected', ({ sessionId }) => {
//       console.log("üé§ STT connected for session:", sessionId)
//     })

//     // Interview events
//     socket.on('interviewStarted', ({ sessionId, question }) => {
//       console.log("üéØ Interview started:", { sessionId, question })
      
//       const newSession: InterviewSession = {
//         id: sessionId,
//         userId: "user-123",
//         status: "active",
//         currentQuestionIndex: 0,
//         totalQuestions: 5,
//         startedAt: new Date(),
//         progress: 20,
//       }
      
//       setSession(newSession)
      
//       if (question?.questionText) {
//         setCurrentQuestion({
//           id: `q-${sessionId}-1`,
//           sessionId,
//           questionIndex: 1,
//           questionText: question.questionText,
//           generatedAt: new Date(),
//         })
//       }
      
//       setProgress(20)
//       setInterviewState("active")
//     })

//     socket.on('interimTranscript', (data) => {
//       setInterimTranscript(data.text)
//     })

//     socket.on('transcript', (data) => {
//       console.log("üìù Final transcript received:", data.text)
//       setTranscript((prev) => [...prev, data.text])
//       setInterimTranscript("")
//       setInterviewState("processing")
//     })

//     socket.on('audioGenerated', (data) => {
//       console.log("üîä Audio generated:", data)
//       setAudioUrl(data.audioUrl)
//       setInterviewState("waiting_for_next")
//       setIsPlaying(false)
      
//       // Auto-play the generated audio
//       if (data.audioUrl) {
//         setTimeout(() => {
//           playAudio(data.audioUrl)
//         }, 500)
//       }
//     })

//     socket.on('interviewComplete', (data) => {
//       console.log("üèÅ Interview completed:", data)
//       setInterviewState("completed")
//       setProgress(100)
//       if (data.responses) {
//         setResponses(data.responses)
//       }
//       cleanup()
//     })

//     socket.on('error', (err) => {
//       console.error("‚ùå Interview error:", err)
//       setError(err)
//     })

//     eventHandlersSetup.current = true
//   }, [cleanup, playAudio])

//   const connectSocket = useCallback(async (): Promise<Socket> => {
//     try {
//       // Cleanup existing socket
//       if (socketRef.current) {
//         socketRef.current.removeAllListeners()
//         socketRef.current.disconnect()
//       }

//       // Get a fresh socket instance
//       const socket = await SingletonSocket.getInstance()
//       socketRef.current = socket
      
//       setupEventHandlers(socket)
      
//       // Set up reconnection handling
//       const handleReconnectAttempt = () => {
//         console.log("üîÑ Attempting to reconnect...")
//         cleanup() // Clean up media resources during reconnection
//       }

//       const handleReconnect = () => {
//         console.log("‚úÖ Socket reconnected")
//         if (session?.id) {
//           console.log("üîÑ Re-establishing session:", session.id)
//           socket.emit("reestablishSession", { 
//             sessionId: session.id,
//             techStack: localStorage.getItem('techStack'),
//             position: localStorage.getItem('position')
//           })
//         }
//       }

//       const handleReconnectError = (error: Error) => {
//         console.error("‚ùå Reconnection error:", error)
//         setError("Connection lost. Trying to reconnect...")
//         cleanup() // Clean up media resources on reconnection error
//       }

//       socket.io.on("reconnect_attempt", handleReconnectAttempt)
//       socket.io.on("reconnect", handleReconnect)
//       socket.io.on("reconnect_error", handleReconnectError)

//       // Return socket with cleanup function
//       const cleanupSocket = () => {
//         socket.io.off("reconnect_attempt", handleReconnectAttempt)
//         socket.io.off("reconnect", handleReconnect)
//         socket.io.off("reconnect_error", handleReconnectError)
//       }

//       Object.defineProperty(socket, 'cleanupEventListeners', {
//         value: cleanupSocket,
//         enumerable: false
//       })

//       return socket

//     } catch (error) {
//       console.error('Failed to connect socket:', error)
//       cleanup() // Clean up on connection failure
//       throw error
//     }
//   }, [setupEventHandlers, session?.id, cleanup])

//   const initializeSpeechRecognition = useCallback(() => {
//     if (typeof window !== "undefined" && "webkitSpeechRecognition" in window) {
//       try {
//         const recognition = new (window as any).webkitSpeechRecognition()
//         recognition.continuous = true
//         recognition.interimResults = true
//         recognition.lang = "en-US"
//         recognition.maxAlternatives = 1

//         // Add these parameters to improve reliability
//         recognition.interimResults = true
//         recognition.maxAlternatives = 3
//         recognition.continuous = false // Change to false to prevent auto-restart

//         let retryCount = 0
//         const maxRetries = 3

//         recognition.onstart = () => {
//           console.log('üé§ Speech recognition started')
//           setError(null)
//           retryCount = 0
//         }

//         recognition.onresult = (event: any) => {
//           let interim = ""
//           let final = ""
          
//           for (let i = event.resultIndex; i < event.results.length; i++) {
//             const transcript = event.results[i][0].transcript
//             if (event.results[i].isFinal) {
//               final += transcript
//             } else {
//               interim += transcript
//             }
//           }
          
//           if (interim && socketRef.current?.connected && session?.id) {
//             setInterimTranscript(interim)
//           }
          
//           if (final && socketRef.current?.connected && session?.id) {
//             console.log("üìù Sending final transcript:", final)
//             socketRef.current.emit("transcript", {
//               sessionId: session.id,
//               text: final,
//               confidence: event.results[event.results.length - 1][0].confidence,
//             })
//           }
//         }

//         recognition.onerror = (e: any) => {
//           console.error("Speech recognition error:", e.error)
          
//           if (e.error === 'network') {
//             if (retryCount < maxRetries) {
//               retryCount++
//               console.log(`üîÑ Retrying speech recognition (${retryCount}/${maxRetries})...`)
//               setTimeout(() => {
//                 if (isRecordingRef.current) {
//                   recognition.start()
//                 }
//               }, 1000)
//               return
//             }
//           }
          
//           if (e.error !== 'no-speech') {
//             setError(`Speech recognition error: ${e.error}. Please try again.`)
//           }
          
//           // Only stop recording if we're not retrying
//           if (retryCount >= maxRetries || e.error !== 'network') {
//             setIsRecording(false)
//             isRecordingRef.current = false
//           }
//         }

//         recognition.onend = () => {
//           console.log('üé§ Speech recognition ended')
//           // Only stop if we're not retrying and still recording
//           if (retryCount >= maxRetries || !isRecordingRef.current) {
//             setIsRecording(false)
//             isRecordingRef.current = false
//           }
//         }

//         recognitionRef.current = recognition
//         console.log('‚úÖ Speech recognition initialized')
//       } catch (error) {
//         console.error('Failed to initialize speech recognition:', error)
//         setError('Speech recognition not supported')
//       }
//     } else {
//       setError('Speech recognition not supported in this browser')
//     }
//   }, [session?.id])

 



//   const stopRecording = useCallback(() => {
//     if (!isRecordingRef.current) {
//       console.log('‚ö†Ô∏è Not currently recording')
//       return
//     }

//     console.log('üõë Stopping recording...')
    
//     try {
//       // First stop media recorder to ensure all data is collected
//       if (mediaRecorderRef.current?.state === "recording") {
//         mediaRecorderRef.current.stop()
//         console.log('‚úÖ Media recorder stopped')
//       }
      
//       // Then stop speech recognition
//       if (recognitionRef.current) {
//         recognitionRef.current.stop()
//         console.log('‚úÖ Speech recognition stopped')
//       }
      
//       // Update state
//       setIsRecording(false)
//       setInterviewState("processing")
//       isRecordingRef.current = false

//       // Clean up media streams
//       if (mediaStreamRef.current) {
//         mediaStreamRef.current.getTracks().forEach(track => {
//           track.stop()
//           console.log('‚úÖ Media track stopped:', track.kind)
//         })
//         mediaStreamRef.current = null
//       }

//     } catch (e) {
//       console.error("Error stopping recording:", e)
//       // Force state reset even if error occurs
//       setIsRecording(false)
//       setInterviewState("processing")
//       isRecordingRef.current = false
//       cleanup() // Ensure everything is cleaned up
//     }
//   }, [cleanup])


//    const initializeMediaRecorder = useCallback(async () => {
//     try {
//       // Clean up existing media stream
//       if (mediaStreamRef.current) {
//         mediaStreamRef.current.getTracks().forEach(track => track.stop())
//       }

//       console.log('üé§ Requesting microphone access...')
//       const stream = await navigator.mediaDevices.getUserMedia({
//         audio: {
//           sampleRate: 16000,
//           channelCount: 1,
//           echoCancellation: true,
//           noiseSuppression: true,
//           autoGainControl: true,
//         },
//       })

//       mediaStreamRef.current = stream
//       console.log('‚úÖ Microphone access granted')

//       const recorder = new MediaRecorder(stream, {
//         mimeType: MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
//           ? 'audio/webm;codecs=opus' 
//           : 'audio/webm',
//       })

//       recorder.ondataavailable = async (e) => {
//         if (e.data.size > 0) {
//           try {
//             // Only process if recording is still active
//             if (!isRecordingRef.current) {
//               console.log('‚ö†Ô∏è Recording stopped, ignoring audio chunk')
//               return
//             }

//             // Check session and connection
//             if (!session?.id || !socketRef.current?.connected) {
//               throw new Error('No active session or connection')
//             }

//             const buffer = await e.data.arrayBuffer()
//             const audioData = Array.from(new Uint8Array(buffer))
            
//             // Add to local buffer first
//             audioChunksRef.current.push(e.data)
            
//             // Validate session with timeout
//             const validSession = await Promise.race([
//               new Promise<boolean>((resolve) => {
//                 socketRef.current?.emit('validateSession', { sessionId: session.id }, (response: { valid: boolean }) => {
//                   resolve(response.valid)
//                 })
//               }),
//               new Promise<boolean>((_, reject) => {
//                 setTimeout(() => reject(new Error('Session validation timeout')), 3000)
//               })
//             ])

//             if (!validSession) {
//               throw new Error('Session expired')
//             }

//             // Send chunk with sequence number and timestamp
//             socketRef.current?.emit("audioChunk", {
//               sessionId: session.id,
//               audioData,
//               timestamp: Date.now(),
//               sequence: audioChunksRef.current.length,
//             })

//           } catch (error) {
//             console.error('Failed to process audio chunk:', error)
//             const errorMessage = error instanceof Error ? error.message : 'Audio processing error'
            
//             if (errorMessage.includes('Session expired') || errorMessage.includes('No active session')) {
//               stopRecording()
//               setError('Session expired. Please restart the interview.')
//             }
//           }
//         }
//       }
      
//       recorder.onstart = () => {
//         console.log('üé§ Media recorder started')
//         audioChunksRef.current = []
//       }

//       recorder.onstop = async () => {
//         console.log('üé§ Media recorder stopped')
        
//         const blob = new Blob(audioChunksRef.current, {
//           type: recorder.mimeType,
//         })
//         audioChunksRef.current = []
        
//         if (session?.id && socketRef.current?.connected) {
//           const arrayBuffer = await blob.arrayBuffer()
//           socketRef.current.emit("finalizeAudio", {
//             sessionId: session.id,
//             audioData: Array.from(new Uint8Array(arrayBuffer)),
//           })
//         }
//       }

//       recorder.onerror = (e) => {
//         console.error('Media recorder error:', e)
//         setError('Recording error occurred')
//         setIsRecording(false)
//         isRecordingRef.current = false
//       }

//       mediaRecorderRef.current = recorder
//       console.log('‚úÖ Media recorder initialized')
//     } catch (e) {
//       console.error("Failed to initialize media recorder:", e)
//       setError("Failed to access microphone")
//     }
//   }, [session?.id, stopRecording])


//     // Main interview controls
//   const startInterview = useCallback(async (
//     techStack = "JavaScript, React, Node.js",
//     position = "Software Developer"
//   ) => {
//     setError(null)
//     setInterviewState("connecting")
    
//     try {
//       console.log("üîå Connecting to server...")
//       const socket = await connectSocket()
      
//       console.log("üì§ Sending startInterview message...")
//       socket.emit("startInterview", { techStack, position })
      
//       // Initialize media components after connection
//       await initializeMediaRecorder()
//       initializeSpeechRecognition()
      
//     } catch (err) {
//       console.error("‚ùå Failed to start interview:", err)
//       setError("Failed to connect to server. Please try again.")
//       setInterviewState("idle")
//     }
//   }, [connectSocket, initializeMediaRecorder, initializeSpeechRecognition])

//   const startRecording = useCallback(async () => {
//     // If already recording, do nothing
//     if (isRecordingRef.current) {
//       console.log('‚ö†Ô∏è Recording already in progress')
//       return
//     }

//     try {
//       // Re-initialize media recorder to ensure fresh state
//       await initializeMediaRecorder()
//       initializeSpeechRecognition()

//       if (!recognitionRef.current || !mediaRecorderRef.current) {
//         throw new Error('Media components not initialized')
//       }

//       if (interviewState !== "active" && interviewState !== "waiting_for_next") {
//         throw new Error('Cannot record in current state: ' + interviewState)
//       }

//       console.log('üé§ Starting recording...')
//       setIsRecording(true)
//       setInterimTranscript("")
//       setError(null)
//       isRecordingRef.current = true
      
//       // Start media recorder first
//       mediaRecorderRef.current.start(100) // Record in 100ms chunks
//       console.log('‚úÖ Media recorder started')

//       // Then start speech recognition
//       recognitionRef.current.start()
//       console.log('‚úÖ Speech recognition started')

//     } catch (e) {
//       console.error("Failed to start recording:", e)
//       setError(e instanceof Error ? e.message : "Failed to start recording")
//       setIsRecording(false)
//       isRecordingRef.current = false
//       cleanup() // Clean up any partial initialization
//     }
//   }, [interviewState, initializeMediaRecorder, initializeSpeechRecognition, cleanup])

//   // Effects
//   useEffect(() => {
//     if (typeof window === 'undefined') return

//     const startFromPreferences = () => {
//       const preferences = localStorage.getItem('interviewPreferences')
//       if (preferences && interviewState === 'idle') {
//         try {
//           const { techStack, position } = JSON.parse(preferences)
//           console.log("üöÄ Auto-starting interview with preferences:", { techStack, position })
//           startInterview(techStack, position)
//           localStorage.removeItem('interviewPreferences')
//         } catch (error) {
//           console.error('Failed to parse interview preferences:', error)
//           localStorage.removeItem('interviewPreferences')
//         }
//       }
//     }

//     startFromPreferences()

//     // Cleanup function
//     return () => {
//       cleanup()
//       SingletonSocket.disconnect()
//     }
//   }, [cleanup, startInterview, interviewState])

//   useEffect(() => {
//     return cleanup
//   }, [cleanup])

//   return {
//     session,
//     currentQuestion: currentQuestion?.questionText || "",
//     transcript,
//     interimTranscript,
//     isRecording,
//     isPlaying,
//     audioUrl,
//     interviewState,
//     progress,
//     responses,
//     error,
//     isConnected,

//     startInterview,
//     stopRecording,
//     startRecording,
//     playAudio,
//     pauseAudio,
//     nextQuestion,
//     endInterview,

//     clearError: () => setError(null),
//   }
// }
